{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a929ae76-b1b8-493e-82c3-9a4fb717bc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6669 - accuracy: 0.8159 - val_loss: 0.3747 - val_accuracy: 0.8897\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3575 - accuracy: 0.8956 - val_loss: 0.3182 - val_accuracy: 0.9069\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.3221 - accuracy: 0.9043 - val_loss: 0.2823 - val_accuracy: 0.9183\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2872 - accuracy: 0.9164 - val_loss: 0.2758 - val_accuracy: 0.9167\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2651 - accuracy: 0.9224 - val_loss: 0.2394 - val_accuracy: 0.9329\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2403 - accuracy: 0.9301 - val_loss: 0.2228 - val_accuracy: 0.9362\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.2215 - accuracy: 0.9351 - val_loss: 0.1952 - val_accuracy: 0.9438\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2034 - accuracy: 0.9419 - val_loss: 0.1832 - val_accuracy: 0.9461\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1857 - accuracy: 0.9459 - val_loss: 0.1662 - val_accuracy: 0.9514\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1727 - accuracy: 0.9497 - val_loss: 0.1677 - val_accuracy: 0.9487\n",
      "Test loss: 0.16765861213207245\n",
      "Test accuracy: 0.9487000107765198\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape the data to be a 2D array\n",
    "X_train = X_train.reshape(X_train.shape[0], 28 * 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28 * 28)\n",
    "\n",
    "# Scale the pixel values between 0 and 1\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# Invert the 0s and 1s\n",
    "X_train = 1 - X_train\n",
    "X_test = 1 - X_test\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {scores[0]}')\n",
    "print(f'Test accuracy: {scores[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7581419e-56a1-41bf-84c5-59c9fef40eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3779 - accuracy: 0.8855 - val_loss: 0.2101 - val_accuracy: 0.9374\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.1915 - accuracy: 0.9435 - val_loss: 0.1595 - val_accuracy: 0.9541\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1411 - accuracy: 0.9580 - val_loss: 0.1305 - val_accuracy: 0.9611\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1149 - accuracy: 0.9653 - val_loss: 0.1084 - val_accuracy: 0.9672\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0970 - accuracy: 0.9708 - val_loss: 0.1009 - val_accuracy: 0.9694\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0857 - accuracy: 0.9745 - val_loss: 0.1018 - val_accuracy: 0.9685\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0751 - accuracy: 0.9769 - val_loss: 0.0863 - val_accuracy: 0.9728\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0675 - accuracy: 0.9784 - val_loss: 0.0929 - val_accuracy: 0.9713\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0624 - accuracy: 0.9805 - val_loss: 0.0858 - val_accuracy: 0.9733\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0570 - accuracy: 0.9814 - val_loss: 0.0969 - val_accuracy: 0.9715\n",
      "Test loss: 0.09685159474611282\n",
      "Test accuracy: 0.9714999794960022\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape the data to be a 2D array\n",
    "X_train = X_train.reshape(X_train.shape[0], 28 * 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28 * 28)\n",
    "\n",
    "# Scale the pixel values between -1 and 1\n",
    "X_train = X_train.astype('float32') / 127.5 - 1\n",
    "X_test = X_test.astype('float32') / 127.5 - 1\n",
    "\n",
    "# Invert the values\n",
    "X_train = -X_train\n",
    "X_test = -X_test\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {scores[0]}')\n",
    "print(f'Test accuracy: {scores[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a87e786d-9de5-47ce-b218-a0dc8fa2d50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 3s 4ms/step - loss: 0.3627 - accuracy: 0.8988 - val_loss: 0.2117 - val_accuracy: 0.9387\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1744 - accuracy: 0.9509 - val_loss: 0.1447 - val_accuracy: 0.9584\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1265 - accuracy: 0.9633 - val_loss: 0.1163 - val_accuracy: 0.9662\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0974 - accuracy: 0.9722 - val_loss: 0.0993 - val_accuracy: 0.9705\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0777 - accuracy: 0.9779 - val_loss: 0.0936 - val_accuracy: 0.9727\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0639 - accuracy: 0.9816 - val_loss: 0.0852 - val_accuracy: 0.9760\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0543 - accuracy: 0.9843 - val_loss: 0.0807 - val_accuracy: 0.9764\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0449 - accuracy: 0.9871 - val_loss: 0.0772 - val_accuracy: 0.9763\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0379 - accuracy: 0.9898 - val_loss: 0.0742 - val_accuracy: 0.9778\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0329 - accuracy: 0.9910 - val_loss: 0.0752 - val_accuracy: 0.9777\n",
      "Test loss: 0.075186587870121\n",
      "Test accuracy: 0.9776999950408936\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape the data to be a 2D array\n",
    "X_train = X_train.reshape(X_train.shape[0], 28 * 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28 * 28)\n",
    "\n",
    "# Scale the pixel values between 0 and 1\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {scores[0]}')\n",
    "print(f'Test accuracy: {scores[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c024e52f-30f6-41d4-8827-1bf2e88c87a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.3959 - accuracy: 0.8918 - val_loss: 0.1853 - val_accuracy: 0.9487\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1681 - accuracy: 0.9528 - val_loss: 0.1326 - val_accuracy: 0.9622\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1227 - accuracy: 0.9653 - val_loss: 0.1344 - val_accuracy: 0.9609\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.1017 - accuracy: 0.9703 - val_loss: 0.1095 - val_accuracy: 0.9697\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0873 - accuracy: 0.9746 - val_loss: 0.0994 - val_accuracy: 0.9711\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0746 - accuracy: 0.9777 - val_loss: 0.1057 - val_accuracy: 0.9702\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 6s 4ms/step - loss: 0.0677 - accuracy: 0.9798 - val_loss: 0.0951 - val_accuracy: 0.9727\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0597 - accuracy: 0.9823 - val_loss: 0.0901 - val_accuracy: 0.9756\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 5s 3ms/step - loss: 0.0572 - accuracy: 0.9826 - val_loss: 0.1106 - val_accuracy: 0.9707\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 5s 4ms/step - loss: 0.0513 - accuracy: 0.9842 - val_loss: 0.0922 - val_accuracy: 0.9739\n",
      "Test loss: 0.09219223260879517\n",
      "Test accuracy: 0.9739000201225281\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape the data to be a 2D array\n",
    "X_train = X_train.reshape(X_train.shape[0], 28 * 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28 * 28)\n",
    "\n",
    "# Create the three different versions of the dataset\n",
    "X_train_original = X_train.astype('float32') / 255\n",
    "X_test_original = X_test.astype('float32') / 255\n",
    "\n",
    "X_train_inverted = 1 - X_train_original\n",
    "X_test_inverted = 1 - X_test_original\n",
    "\n",
    "X_train_scaled = X_train.astype('float32') / 127.5 - 1\n",
    "X_test_scaled = X_test.astype('float32') / 127.5 - 1\n",
    "\n",
    "# Combine the three datasets into one\n",
    "X_train_combined = np.concatenate((X_train_original, X_train_inverted, X_train_scaled), axis=0)\n",
    "X_test_combined = np.concatenate((X_test_original, X_test_inverted, X_test_scaled), axis=0)\n",
    "\n",
    "# Duplicate the labels to match the combined dataset\n",
    "y_train_combined = np.concatenate((y_train, y_train, y_train), axis=0)\n",
    "y_test_combined = np.concatenate((y_test, y_test, y_test), axis=0)\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_combined, y_train_combined, epochs=10, batch_size=128, verbose=1, validation_data=(X_test_combined, y_test_combined))\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "scores = model.evaluate(X_test_combined, y_test_combined, verbose=0)\n",
    "print(f'Test loss: {scores[0]}')\n",
    "print(f'Test accuracy: {scores[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
